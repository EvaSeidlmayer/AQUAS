

# 2024-06-14
BERT_tokenize_dataset.py

Epoch 1/10
56/56 [==============================] - 755s 13s/step - loss: 7.9276 - accuracy: 0.3016 - val_loss: 8.5106 - val_accuracy: 0.2649
Epoch 2/10
56/56 [==============================] - 746s 13s/step - loss: 8.5171 - accuracy: 0.2698 - val_loss: 7.7261 - val_accuracy: 0.4103
Epoch 3/10
56/56 [==============================] - 734s 13s/step - loss: 7.7126 - accuracy: 0.3107 - val_loss: 8.5380 - val_accuracy: 0.2694
Epoch 4/10
56/56 [==============================] - 734s 13s/step - loss: 8.8083 - accuracy: 0.2880 - val_loss: 8.4741 - val_accuracy: 0.2688
Epoch 5/10
56/56 [==============================] - 731s 13s/step - loss: 9.2834 - accuracy: 0.3220 - val_loss: 8.4741 - val_accuracy: 0.2688
Epoch 6/10
56/56 [==============================] - 729s 13s/step - loss: 8.6634 - accuracy: 0.3061 - val_loss: 10.1981 - val_accuracy: 0.2649
Epoch 7/10
56/56 [==============================] - 724s 13s/step - loss: 8.4063 - accuracy: 0.2766 - val_loss: 8.4102 - val_accuracy: 0.2677
Epoch 8/10
56/56 [==============================] - 729s 13s/step - loss: 9.0276 - accuracy: 0.3197 - val_loss: 8.4102 - val_accuracy: 0.2688
Epoch 9/10
56/56 [==============================] - 741s 13s/step - loss: 9.0276 - accuracy: 0.3333 - val_loss: 8.4102 - val_accuracy: 0.2688
Epoch 10/10
56/56 [==============================] - 723s 13s/step - loss: 9.4296 - accuracy: 0.3197 - val_loss: 8.4102 - val_accuracy: 0.2688
BERT fine tuned
221/221 [==============================] - 415s 2s/step - loss: 8.4102 - accuracy: 0.2688
56/56 [==============================] - 421s 7s/step
Validation Loss: 8.4102 Accuracy: 0.2688 F1-score: 0.1201





# BERT_training sliding multi label classification. py
## Bert base
[10] Accuracy: 0.9740, F1-score: 0.9737, Classification_report:                           precision    recall  f1-score   support

         class scientific       0.98      1.00      0.99       361
 class popular scientific       0.95      0.98      0.97       464
     class disinformation       0.98      0.95      0.96       488
class alternative science       0.98      0.98      0.98       454

                micro avg       0.97      0.97      0.97      1767
                macro avg       0.97      0.98      0.97      1767
             weighted avg       0.97      0.97      0.97      1767
              samples avg       0.97      0.97      0.97      1767

done
wandb: Waiting for W&B process to finish... (success).
wandb:
wandb: Run history:
wandb: accuracy ‚ñÅ‚ñÜ‚ñÉ‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:       f1 ‚ñÅ‚ñÜ‚ñÉ‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:
wandb: Run summary:
wandb:              accuracy 0.97397
wandb: classification_report                     ...
wandb:                    f1 0.97365
wandb:
wandb: üöÄ View run misunderstood-vortex-225 at: https://wandb.ai/zbmed/AQUAS/runs/gg49iumv
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240620_083952-gg49iumv/logs


## "dmis-lab/biobert-v1.1"
### 10 Epochs

    [10] Accuracy: 0.9728, F1-score: 0.9726, Classification_report:                           precision    recall  f1-score   support

         class scientific       0.96      1.00      0.98       359
 class popular scientific       0.99      0.95      0.97       472
     class disinformation       0.95      0.99      0.97       476
class alternative science       1.00      0.96      0.98       460

                micro avg       0.97      0.97      0.97      1767
                macro avg       0.97      0.97      0.97      1767
             weighted avg       0.97      0.97      0.97      1767
              samples avg       0.97      0.97      0.97      1767

done
wandb: Waiting for W&B process to finish... (success).
wandb:
wandb: Run history:
wandb: accuracy ‚ñÅ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:       f1 ‚ñÅ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:
wandb: Run summary:
wandb:              accuracy 0.97284
wandb: classification_report                     ...
wandb:                    f1 0.97256
wandb:
wandb: üöÄ View run dazzling-capybara-224 at: https://wandb.ai/zbmed/AQUAS/runs/3afbfoyv
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240620_065623-3afbfoyv/logs



## models/bertbase_t10k_e7_lr3e-5_mlclass
10 epochs
[3] Accuracy: 0.9061, F1-score: 0.9067, Classification_report:                           precision    recall  f1-score   support

         class scientific       0.76      1.00      0.86       348
 class popular scientific       0.97      0.96      0.96       478
     class disinformation       0.96      0.92      0.94       488
class alternative science       1.00      0.73      0.84       453

                micro avg       0.92      0.90      0.91      1767
                macro avg       0.92      0.90      0.90      1767
             weighted avg       0.93      0.90      0.91      1767
              samples avg       0.90      0.90      0.90      1767

done
wandb: Waiting for W&B process to finish... (success).
wandb: / 0.398 MB of 0.398 MB uploaded (0.000 MB deduped)
wandb: Run history:
wandb: accuracy ‚ñÇ‚ñà‚ñÅ
wandb:       f1 ‚ñÇ‚ñà‚ñÅ
wandb:
wandb: Run summary:
wandb:              accuracy 0.90606
wandb: classification_report                     ...
wandb:                    f1 0.90671
wandb:
wandb: üöÄ View run hopeful-shadow-215 at: https://wandb.ai/zbmed/AQUAS/runs/9vhc8u4z


bert -base
wandb: Run history:
wandb: accuracy ‚ñÅ‚ñÜ‚ñà
wandb:       f1 ‚ñÅ‚ñá‚ñà
wandb:
wandb: Run summary:
wandb:              accuracy 0.96265
wandb: classification_report                     ...
wandb:                    f1 0.96159
wandb:
wandb: üöÄ View run electric-tree-216 at: https://wandb.ai/zbmed/AQUAS/runs/4abis1fb
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)




## scibert
[10] Accuracy: 0.9768, F1-score: 0.9777, Classification_report:                           precision    recall  f1-score   support

         class scientific       0.96      1.00      0.98       355
 class popular scientific       0.96      0.99      0.97       464
     class disinformation       0.99      0.97      0.98       470
class alternative science       1.00      0.96      0.98       478

                micro avg       0.98      0.98      0.98      1767
                macro avg       0.98      0.98      0.98      1767
             weighted avg       0.98      0.98      0.98      1767
              samples avg       0.98      0.98      0.98      1767

done
wandb: Waiting for W&B process to finish... (success).
wandb:
wandb: Run history:
wandb: accuracy ‚ñÜ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:       f1 ‚ñá‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:
wandb: Run summary:
wandb:              accuracy 0.9768
wandb: classification_report                     ...
wandb:                    f1 0.97769
wandb:
wandb: üöÄ View run rural-night-223 at: https://wandb.ai/zbmed/AQUAS/runs/3idg5xnq




##SPECTER
[10] Accuracy: 0.9813, F1-score: 0.9827,
Classification_report:
           precision    recall  f1-score   support

         class scientific       1.00      1.00      1.00       364
 class popular scientific       0.98      0.97      0.97       464
     class disinformation       0.98      0.96      0.97       474
class alternative science       0.97      1.00      0.99       465

                micro avg       0.98      0.98      0.98      1767
                macro avg       0.98      0.98      0.98      1767
             weighted avg       0.98      0.98      0.98      1767
              samples avg       0.98      0.98      0.98      1767

done
wandb: Waiting for W&B process to finish... (success).
wandb: / 0.406 MB of 0.406 MB uploaded (0.000 MB deduped)
wandb: Run history:
wandb: accuracy ‚ñá‚ñà‚ñà‚ñá‚ñÅ‚ñá‚ñà‚ñà‚ñà‚ñà
wandb:       f1 ‚ñá‚ñà‚ñà‚ñá‚ñÅ‚ñá‚ñà‚ñà‚ñà‚ñà
wandb:
wandb: Run summary:
wandb:              accuracy 0.98132
wandb: classification_report                     ...
wandb:                    f1 0.98267
üöÄ View run worthy-feather-220 at: https://wandb.ai/zbmed/AQUAS/runs/l9c9huok
